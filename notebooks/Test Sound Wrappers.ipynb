{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee4ac28",
   "metadata": {},
   "source": [
    "In this notebook we will test if our audio wrappers are working correctly. The wrappers to be tested are RetroSound and FFTWrapper. By testing them, we will make sure that the agent receives the audio and can learn from it.\n",
    "To do it, we will make a simple toy environment, where to solve the problem, the agents needs to process audio in a sensible way.\n",
    "\n",
    "We will code a 1D game with two potential goals, picked at random on each episode. Agent receives a sine wave with frequency propotional to distance to the correct goal. Without audio info it will learn to pick goals at random or always pick one of them. With sound info it should learn to go correct goal all the time.\n",
    "Here is what the environment will look like:\n",
    "\n",
    "\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ <br>\n",
    "| 0  1  2  3  4  5  6  7  8 |<br>\n",
    "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
    " \n",
    "We start the game at a random position [2-6]. We can move left or right, we get a negative reward of -0.025 on each step. The correct goal is either 0 or 8, which will give us a reward of 1. If we reach the wrong goal, we will get a reward -1 and the game will finish. The closer we are to the correct goal, the higher is the frequency of sin wave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564b7c3",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bed18",
   "metadata": {},
   "source": [
    "Works with colab, adjust for conda/widnows/etc... if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb08251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install -q gym-retro\n",
    "\n",
    "# Get my version of stable-baselines3 with audio support\n",
    "!git clone -b gym-to-retro https://github.com/rienath/stable-baselines3.git\n",
    "!mv stable-baselines3/stable_baselines3 stable_baselines3\n",
    "!rm -rf stable-baselines3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedef61b",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "import gym\n",
    "import numpy as np\n",
    "import stable_baselines3\n",
    "from stable_baselines3.ppo import PPO\n",
    "from stable_baselines3.common.atari_wrappers import RetroSound, FFTWrapper\n",
    "from stable_baselines3.common.type_aliases import GymStepReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39fea56",
   "metadata": {},
   "source": [
    "Define the classes that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class emulator():\n",
    "    \"\"\"\n",
    "    This class models retro emulator that can return audio to make env.em.get_audio() possible in the wrappers.\n",
    "    \"\"\"\n",
    "    def __init__(self, audio):\n",
    "        self.audio = audio\n",
    "\n",
    "    def get_audio(self):\n",
    "        return self.audio\n",
    "    \n",
    "    def update_audio(self, audio):\n",
    "        self.audio = audio \n",
    "\n",
    "\n",
    "class AudioMultiObsEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    GridWorld-based MultiObs Environments 1x8.\n",
    "        ___________________________\n",
    "       | 0  1  2  3  4  5  6  7  8 |\n",
    "       ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
    "    start is 4 or random\n",
    "    goal is 0 or 8, randomly determined in every round\n",
    "    if we reach incorrect goal, we get punished (reward -1)\n",
    "    if we reach correct goal, we get rewarded (reward -1)\n",
    "    actions are = [left, right]\n",
    "    each state is represented by a random image\n",
    "    each state has stereo audio; the closer state is to goal, the higher the frequency\n",
    "    each step has a punishment (reward -0.025)\n",
    "    :param num_col: Number of columns in the grid\n",
    "    :param random_start: If true, agent starts in random position apart from the goal/false-goal positions and states directly next to them\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_col: int = 9,\n",
    "        random_start: bool = True\n",
    "    ):\n",
    "        super(AudioMultiObsEnv, self).__init__()\n",
    "\n",
    "        self.img_size = [84, 84, 1]\n",
    "\n",
    "        self.random_start = random_start\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            spaces={\n",
    "                \"obs\": gym.spaces.Box(0, 255, self.img_size, dtype=np.uint8),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.count = 0\n",
    "        self.max_count = 20 # Number of maximum steps\n",
    "        self.log = \"\"\n",
    "        self.state = 4\n",
    "        self.action2str = [\"left\", \"right\"]\n",
    "        self.init_possible_transitions()\n",
    "        self.num_col = num_col\n",
    "        self.state_mapping = []\n",
    "        self.sounds = []\n",
    "        self.init_state_mapping()\n",
    "        self.min_state = 0\n",
    "        self.max_state = num_col - 1\n",
    "        self.win_state = np.random.choice([self.min_state, self.max_state])\n",
    "        self.update_state_mapping()\n",
    "        self.em = emulator(self.get_state_mapping()[\"sound\"]) # Makes env.em.get_audio possible for wrappers\n",
    "\n",
    "\n",
    "    def init_state_mapping(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the state_mapping array which holds the observation values for each state\n",
    "        \"\"\"\n",
    "\n",
    "        # Each state is represented by a random image\n",
    "        col_imgs = np.random.randint(0, 255, (self.num_col, 84, 84), dtype=np.int32)\n",
    "\n",
    "        # Each state is represented by sin wave of a certain frequency. The closer the state is to the goal\n",
    "        # the higher the frequency.\n",
    "        for i in range(self.num_col):\n",
    "            # Get x values of the sin wave\n",
    "            time = np.arange(0, 524, 1)\n",
    "            frequency = i*100\n",
    "            # Amplitude of the sine wave is sine of freauency * time\n",
    "            amplitude = np.sin(frequency*time)\n",
    "            # Get the amplitude to format [[l, r], [l, r]...] and so on as this is the representation\n",
    "            # of stereo audio in retro.\n",
    "            stereo_waves = np.transpose([amplitude, amplitude])\n",
    "            self.sounds.append(stereo_waves)\n",
    "        \n",
    "        # Arrange sounds as if goal is the last state by default\n",
    "        for i in range(self.num_col):\n",
    "            self.state_mapping.append({\"obs\":   col_imgs[i].reshape(self.img_size),\n",
    "                                       \"sound\": self.sounds[i]})\n",
    "    \n",
    "    def update_state_mapping(self):\n",
    "        # If win state is the minimal state, leave sounds be.\n",
    "        # If not, reverse them as the goal is in the other end of the tunnel.\n",
    "        if self.win_state == self.min_state:\n",
    "            for i in range(self.num_col):\n",
    "                self.state_mapping[i][\"sound\"] = self.sounds[i]\n",
    "        else:\n",
    "            sounds_reversed = self.sounds[::-1]\n",
    "            for i in range(self.num_col):\n",
    "                self.state_mapping[i][\"sound\"] = sounds_reversed[i]\n",
    "\n",
    "    def get_state_mapping(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Uses the state to get the observation mapping.\n",
    "        :return: observation dict\n",
    "        \"\"\"\n",
    "        return self.state_mapping[self.state]\n",
    "\n",
    "    def init_possible_transitions(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the transitions of the environment.\n",
    "        \"\"\"\n",
    "        self.left_possible = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        self.right_possible = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        self.down_possible = []\n",
    "        self.up_possible = []\n",
    "\n",
    "    def step(self, action: Union[int, float, np.ndarray]) -> GymStepReturn:\n",
    "        \"\"\"\n",
    "        Run one timestep of the environment's dynamics. When end of\n",
    "        episode is reached, you are responsible for calling `reset()`\n",
    "        to reset this environment's state.\n",
    "        Accepts an action and returns a tuple (observation, reward, done, info).\n",
    "        :param action:\n",
    "        :return: tuple (observation, reward, done, info).\n",
    "        \"\"\"\n",
    "        action = int(action)\n",
    "\n",
    "        self.count += 1\n",
    "\n",
    "        prev_state = self.state\n",
    "\n",
    "        reward = -0.025\n",
    "        # Define state transition\n",
    "        if self.state in self.left_possible and action == 0:  # left\n",
    "            self.state -= 1\n",
    "        elif self.state in self.right_possible and action == 1:  # right\n",
    "            self.state += 1\n",
    "\n",
    "        got_to_end = self.state == self.max_state or self.state == self.min_state\n",
    "        if got_to_end:\n",
    "            reward = 1 if self.state == self.win_state else -1\n",
    "        done = self.count > self.max_count or got_to_end\n",
    "\n",
    "        self.log = f\"Went {self.action2str[action]} in state {prev_state}, got to state {self.state}\"\n",
    "\n",
    "        # Update audio in emulator\n",
    "        self.em.update_audio(self.get_state_mapping()[\"sound\"])\n",
    "\n",
    "        return {\"obs\": self.get_state_mapping()[\"obs\"]}, reward, done, {\"got_to_end\": got_to_end}\n",
    "\n",
    "    def render(self, mode: str = \"human\") -> None:\n",
    "        \"\"\"\n",
    "        Prints the log of the environment.\n",
    "        :param mode:\n",
    "        \"\"\"\n",
    "        print(self.log)\n",
    "\n",
    "    def reset(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Resets the environment state and step count and returns reset observation.\n",
    "        \"\"\"\n",
    "        self.count = 0\n",
    "        self.win_state = np.random.choice([self.min_state, self.max_state])\n",
    "        # Update frequencies of states as the goal might have changed.\n",
    "        self.update_state_mapping()\n",
    "        if not self.random_start:\n",
    "            self.state = 4\n",
    "        else:\n",
    "            self.state = np.random.randint(2, self.max_state - 2)\n",
    "        # Update audio in emulator\n",
    "        self.em.update_audio(self.get_state_mapping()[\"sound\"])\n",
    "        return {\"obs\": self.get_state_mapping()[\"obs\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668bde3",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./AUDIO_TEST/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5ff2b",
   "metadata": {},
   "source": [
    "## Just image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AudioMultiObsEnv()\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=\"./AUDIO_TEST/\")\n",
    "model.learn(total_timesteps=200000)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74257ae0",
   "metadata": {},
   "source": [
    "## Image + raw audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb988345",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AudioMultiObsEnv()\n",
    "env = RetroSound(env)\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=\"./AUDIO_TEST/\")\n",
    "model.learn(total_timesteps=200000)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b79c8c",
   "metadata": {},
   "source": [
    "## Image + FFT audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284261a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AudioMultiObsEnv()\n",
    "env = RetroSound(env)\n",
    "env = FFTWrapper(env)\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=\"./AUDIO_TEST/\")\n",
    "model.learn(total_timesteps=200000)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
